{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa868e73-68a9-4ea2-bff0-29e6f5508c2b",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fddc694d-b8d8-457c-9436-cfc06ec6a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "%matplotlib inline\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Lambda ,Dense ,Flatten ,Dropout\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e288d0b5-9d34-432c-b3d5-85028e471403",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be90562b-0061-42ba-9ed0-46270fc24da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"ArSL_Data_Labels.csv\")\n",
    "labels = labels.drop(columns=\"#\")\n",
    "new_labels = [(labels[\"Class\"][item], labels[\"File_Name\"][item]) for item in labels.index]\n",
    "images = [cv.imread(\"ArASL_Database_54K_Final/\"+cl+\"/\"+f) for cl, f in new_labels]\n",
    "# img = cv.imread(\"ArASL_Database_54K_Final/ain/AIN (1).JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc42b304-4a1d-4b71-9975-ff6c33bd106f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Numbers of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "340d1ddb-2453-4199-8fa2-d5bfead802cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers of images is  54049 (54049, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"numbers of images is \", len(images), labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adf8e30-1a23-42db-ac00-9b6acb8e0095",
   "metadata": {},
   "source": [
    "#### Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e779b90-d0ee-48c3-af90-34b3e8b7744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dico_size(shapes):\n",
    "    dico = {}\n",
    "    for shape in shapes:\n",
    "        if dico.get(shape, False) == False:\n",
    "            dico[shape] = 1\n",
    "        else: \n",
    "            dico[shape] = dico[shape] + 1\n",
    "    return dico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa0d54-e3bd-4c7d-95d8-bbdededff680",
   "metadata": {},
   "source": [
    "#### Visualize images sizes in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c20e6ccd-e6bb-46e2-8faa-06d32f3ffc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(64, 64, 3): 53401, (256, 256, 3): 638, (1024, 768, 3): 10}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes = [img.shape for img in images]\n",
    "shapes_sorted = sorted(shapes)\n",
    "dico_size(shapes_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f827bea6-9cf4-4bb3-b1ba-45fa971c00ae",
   "metadata": {},
   "source": [
    "#### Resize all images to (64x64x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb193e7a-3bd2-47c8-b8ec-d8a2b4fa40d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_resized = []\n",
    "for img in images:\n",
    "    if img.shape != (64, 64, 3):\n",
    "        img = cv.resize(img, (64, 64), interpolation = cv.INTER_AREA)\n",
    "    images_resized.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e36b68a6-acd0-4064-ae55-efa1c6fe763b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(64, 64, 3): 54049}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico_size(sorted([img.shape for img in images_resized]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6e7549a-e4a6-4078-a0ac-f0bb980f1f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54049, 64, 64, 3) (54049,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(images_resized)\n",
    "y = labels[\"Class\"].to_numpy()\n",
    "print(data.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f35e218-81e5-4732-8ac1-4d93f6c2fcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (43239, 64, 64, 3) y_train (43239,) \n",
      "x_test (10810, 64, 64, 3) y_test (10810,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size = 0.2)\n",
    "\n",
    "print(\"x_train\", X_train.shape, \"y_train\", y_train.shape, \"\\nx_test\", X_test.shape, \"y_test\", y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
